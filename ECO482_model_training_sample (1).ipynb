{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yr-wlw511d8z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oX3yHo6J1Z_I"
   },
   "outputs": [],
   "source": [
    "# Read File\n",
    "file_path = 'cleaned.csv'\n",
    "hmda = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmda_sample = hmda.sample(frac =.10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2486666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hmda_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "h82ylM9D3sDs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "as_of_year                          int64\n",
       "action_taken                        int64\n",
       "loan_type                           int64\n",
       "loan_purpose                        int64\n",
       "loan_amount_000s                  float64\n",
       "msamd                             float64\n",
       "state_code                        float64\n",
       "county_code                       float64\n",
       "applicant_ethnicity                 int64\n",
       "co_applicant_ethnicity              int64\n",
       "applicant_race_1                    int64\n",
       "co_applicant_race_1                 int64\n",
       "applicant_sex                       int64\n",
       "co_applicant_sex                    int64\n",
       "applicant_income_000s             float64\n",
       "purchaser_type                      int64\n",
       "rate_spread                       float64\n",
       "hoepa_status                        int64\n",
       "population                        float64\n",
       "minority_population               float64\n",
       "hud_median_family_income          float64\n",
       "tract_to_msamd_income             float64\n",
       "number_of_owner_occupied_units    float64\n",
       "number_of_1_to_4_family_units     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmda_sample.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "loTSYYsU72eK"
   },
   "outputs": [],
   "source": [
    "# Dropping rate_spread for now as well\n",
    "X = hmda_sample.drop(columns=['action_taken', 'rate_spread'])\n",
    "y = hmda_sample['action_taken']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LmnxDtcUCiE4"
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LlpoVfOn9LmH"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "t9JXudvJ-lsv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(random_state=42, verbose=2)\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bqL0CZL-mstv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Scores and Confusion Matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "auc_score = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMGHGxOEifaA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "importances = rf_model.feature_importances_\n",
    "features = X.columns\n",
    "plt.barh(features, importances)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmda_nb = GaussianNB()\n",
    "\n",
    "hmda_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95    413621\n",
      "           1       1.00      0.53      0.69     83713\n",
      "\n",
      "    accuracy                           0.92    497334\n",
      "   macro avg       0.95      0.77      0.82    497334\n",
      "weighted avg       0.93      0.92      0.91    497334\n",
      "\n",
      "Confusion Matrix\n",
      "[[413403    218]\n",
      " [ 39169  44544]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = hmda_nb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes model accuracy(in %): 92.0803725464175\n"
     ]
    }
   ],
   "source": [
    "y_pred = hmda_nb.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_mapping = {5: 'White', 3: 'Black or African American', 2: 'Asian', 1: 'American Indian or Alaska Native', 4: 'Native Hawaiian or Other Pacific Islander'}\n",
    "# hmda_sample['action_taken'] = hmda_sample['action_taken'].apply(lambda x: 1 if x in [1, 2] else 0)\n",
    "# hmda_sample['applicant_race_1'] = hmda_sample['applicant_race_1'].map(race_mapping)\n",
    "# hmda_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20493630    5\n",
       "785654      5\n",
       "23721266    5\n",
       "11834421    3\n",
       "5852959     1\n",
       "           ..\n",
       "15768785    3\n",
       "10510466    5\n",
       "18606040    5\n",
       "23705045    5\n",
       "23385277    5\n",
       "Name: applicant_race_1, Length: 2486666, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmda_sample['applicant_race_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the data on white data and then testing on all data\n",
    "# 5 is white\n",
    "white_data = hmda_sample[hmda_sample['applicant_race_1'] == 5]\n",
    "X_white = white_data.drop(columns=['action_taken', 'rate_spread'])\n",
    "y_white = white_data['action_taken']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as_of_year</th>\n",
       "      <th>action_taken</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>loan_amount_000s</th>\n",
       "      <th>msamd</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>applicant_ethnicity</th>\n",
       "      <th>co_applicant_ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>applicant_income_000s</th>\n",
       "      <th>purchaser_type</th>\n",
       "      <th>rate_spread</th>\n",
       "      <th>hoepa_status</th>\n",
       "      <th>population</th>\n",
       "      <th>minority_population</th>\n",
       "      <th>hud_median_family_income</th>\n",
       "      <th>tract_to_msamd_income</th>\n",
       "      <th>number_of_owner_occupied_units</th>\n",
       "      <th>number_of_1_to_4_family_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20493630</th>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>118.0</td>\n",
       "      <td>43900.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>7920.0</td>\n",
       "      <td>16.290001</td>\n",
       "      <td>54800.0</td>\n",
       "      <td>119.900002</td>\n",
       "      <td>2317.0</td>\n",
       "      <td>3005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785654</th>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31084.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4268.0</td>\n",
       "      <td>35.259998</td>\n",
       "      <td>56500.0</td>\n",
       "      <td>154.720001</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>1538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23721266</th>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>209.0</td>\n",
       "      <td>38060.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>7333.0</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>66200.0</td>\n",
       "      <td>130.979996</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>3416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15220120</th>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>181.0</td>\n",
       "      <td>24020.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>5.010000</td>\n",
       "      <td>62600.0</td>\n",
       "      <td>99.370003</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>1750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9401259</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>328.0</td>\n",
       "      <td>17140.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>7708.0</td>\n",
       "      <td>6.330000</td>\n",
       "      <td>69200.0</td>\n",
       "      <td>155.580002</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075418</th>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>164.0</td>\n",
       "      <td>18140.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>5738.0</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>64200.0</td>\n",
       "      <td>113.629997</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>2131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10510466</th>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>305.0</td>\n",
       "      <td>17820.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4485.0</td>\n",
       "      <td>12.910000</td>\n",
       "      <td>70600.0</td>\n",
       "      <td>154.130005</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>1577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18606040</th>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2</td>\n",
       "      <td>4834.0</td>\n",
       "      <td>52.849998</td>\n",
       "      <td>55800.0</td>\n",
       "      <td>105.480003</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23705045</th>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19124.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>17773.0</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>73400.0</td>\n",
       "      <td>165.919998</td>\n",
       "      <td>4815.0</td>\n",
       "      <td>5128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23385277</th>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>23420.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4372.0</td>\n",
       "      <td>92.379997</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>54.410000</td>\n",
       "      <td>592.0</td>\n",
       "      <td>1238.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1959501 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          as_of_year  action_taken  loan_type  loan_purpose  loan_amount_000s  \\\n",
       "20493630        2015             0          2             3             118.0   \n",
       "785654          2007             0          1             1              34.0   \n",
       "23721266        2017             0          2             1             209.0   \n",
       "15220120        2012             0          2             1             181.0   \n",
       "9401259         2009             0          1             3             328.0   \n",
       "...              ...           ...        ...           ...               ...   \n",
       "1075418         2007             0          1             3             164.0   \n",
       "10510466        2010             0          3             3             305.0   \n",
       "18606040        2014             1          2             1             132.0   \n",
       "23705045        2017             0          1             3              42.0   \n",
       "23385277        2017             0          1             3             108.0   \n",
       "\n",
       "            msamd  state_code  county_code  applicant_ethnicity  \\\n",
       "20493630  43900.0        45.0         83.0                    1   \n",
       "785654    31084.0         6.0         37.0                    2   \n",
       "23721266  38060.0         4.0         13.0                    2   \n",
       "15220120  24020.0        36.0        113.0                    2   \n",
       "9401259   17140.0        39.0        165.0                    2   \n",
       "...           ...         ...          ...                  ...   \n",
       "1075418   18140.0        39.0        159.0                    2   \n",
       "10510466  17820.0         8.0         41.0                    2   \n",
       "18606040  41420.0        41.0         47.0                    1   \n",
       "23705045  19124.0        48.0         85.0                    2   \n",
       "23385277  23420.0         6.0         19.0                    2   \n",
       "\n",
       "          co_applicant_ethnicity  ...  applicant_income_000s  purchaser_type  \\\n",
       "20493630                       0  ...                   45.0               0   \n",
       "785654                         2  ...                  371.0               0   \n",
       "23721266                       0  ...                   70.0               0   \n",
       "15220120                       0  ...                   50.0               0   \n",
       "9401259                        2  ...                  149.0               0   \n",
       "...                          ...  ...                    ...             ...   \n",
       "1075418                        0  ...                   46.0               0   \n",
       "10510466                       2  ...                   98.0               0   \n",
       "18606040                       0  ...                   31.0               7   \n",
       "23705045                       2  ...                  112.0               0   \n",
       "23385277                       0  ...                   32.0               0   \n",
       "\n",
       "          rate_spread  hoepa_status  population  minority_population  \\\n",
       "20493630        -1.00             2      7920.0            16.290001   \n",
       "785654          -1.00             2      4268.0            35.259998   \n",
       "23721266        -1.00             2      7333.0            30.400000   \n",
       "15220120        -1.00             2      3731.0             5.010000   \n",
       "9401259         -1.00             2      7708.0             6.330000   \n",
       "...               ...           ...         ...                  ...   \n",
       "1075418         -1.00             2      5738.0             1.850000   \n",
       "10510466        -1.00             2      4485.0            12.910000   \n",
       "18606040         1.57             2      4834.0            52.849998   \n",
       "23705045        -1.00             2     17773.0            33.750000   \n",
       "23385277        -1.00             2      4372.0            92.379997   \n",
       "\n",
       "          hud_median_family_income  tract_to_msamd_income  \\\n",
       "20493630                   54800.0             119.900002   \n",
       "785654                     56500.0             154.720001   \n",
       "23721266                   66200.0             130.979996   \n",
       "15220120                   62600.0              99.370003   \n",
       "9401259                    69200.0             155.580002   \n",
       "...                            ...                    ...   \n",
       "1075418                    64200.0             113.629997   \n",
       "10510466                   70600.0             154.130005   \n",
       "18606040                   55800.0             105.480003   \n",
       "23705045                   73400.0             165.919998   \n",
       "23385277                   50000.0              54.410000   \n",
       "\n",
       "          number_of_owner_occupied_units  number_of_1_to_4_family_units  \n",
       "20493630                          2317.0                         3005.0  \n",
       "785654                            1353.0                         1538.0  \n",
       "23721266                          1982.0                         3416.0  \n",
       "15220120                          1068.0                         1750.0  \n",
       "9401259                           2250.0                         2500.0  \n",
       "...                                  ...                            ...  \n",
       "1075418                           1763.0                         2131.0  \n",
       "10510466                          1261.0                         1577.0  \n",
       "18606040                          1012.0                         1305.0  \n",
       "23705045                          4815.0                         5128.0  \n",
       "23385277                           592.0                         1238.0  \n",
       "\n",
       "[1959501 rows x 24 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20493630    5\n",
       "785654      5\n",
       "23721266    5\n",
       "15220120    5\n",
       "9401259     5\n",
       "           ..\n",
       "1075418     5\n",
       "10510466    5\n",
       "18606040    5\n",
       "23705045    5\n",
       "23385277    5\n",
       "Name: applicant_race_1, Length: 1959501, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_data['applicant_race_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_white_scaled = scaler.fit_transform(X_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmda_nb.fit(X_white_scaled, y_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>ROC-AUC Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White only</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.864321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.441509</td>\n",
       "      <td>0.906636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All races</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.866177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.466737</td>\n",
       "      <td>0.916204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White only</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>500</td>\n",
       "      <td>0.873952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550829</td>\n",
       "      <td>0.924909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All races</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>500</td>\n",
       "      <td>0.880286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.567399</td>\n",
       "      <td>0.932019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White only</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.865381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486669</td>\n",
       "      <td>0.914182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All races</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.867990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.498561</td>\n",
       "      <td>0.921203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White only</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>500</td>\n",
       "      <td>0.882910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557908</td>\n",
       "      <td>0.926091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All races</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>500</td>\n",
       "      <td>0.890341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572601</td>\n",
       "      <td>0.932837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model max_depth bootstrap max_samples  ROC-AUC Score  Precision  \\\n",
       "0  White only         3      True         100       0.864321        1.0   \n",
       "0   All races         3      True         100       0.866177        1.0   \n",
       "1  White only         3      True         500       0.873952        1.0   \n",
       "1   All races         3      True         500       0.880286        1.0   \n",
       "2  White only         5      True         100       0.865381        1.0   \n",
       "2   All races         5      True         100       0.867990        1.0   \n",
       "3  White only         5      True         500       0.882910        1.0   \n",
       "3   All races         5      True         500       0.890341        1.0   \n",
       "\n",
       "     Recall  Accuracy  \n",
       "0  0.441509  0.906636  \n",
       "0  0.466737  0.916204  \n",
       "1  0.550829  0.924909  \n",
       "1  0.567399  0.932019  \n",
       "2  0.486669  0.914182  \n",
       "2  0.498561  0.921203  \n",
       "3  0.557908  0.926091  \n",
       "3  0.572601  0.932837  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up data for machine learning\n",
    "# Create function that creates stratified samples of a dataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def stratified_sample(df, col, sample_size):\n",
    "    \"\"\"Creates a new dataframe that has the same proportions of specified column as the original dataframe\"\"\"\n",
    "    sample = pd.DataFrame()\n",
    "    total_obs = df.shape[0]\n",
    "    grouped = df.groupby(col)\n",
    "    for category in list(grouped.groups.keys()):\n",
    "        group = grouped.get_group(category)\n",
    "        group_size = group.shape[0]\n",
    "        group_sample_size = round((group_size / total_obs) * sample_size)\n",
    "        if sample.shape[0] > 0:\n",
    "            sample = pd.concat([sample, group.sample(n=group_sample_size, random_state=313)], ignore_index=True)\n",
    "        else:\n",
    "            sample = grouped.get_group(category).sample(n=group_sample_size, random_state=313)\n",
    "    return sample\n",
    "\n",
    "# Function that collects all data for a specific year\n",
    "def set_year(df, year):\n",
    "    \"\"\"Creates a new dataframe that contains all observations for a specific year\"\"\"\n",
    "    year_data = df[df['as_of_year'] == year]\n",
    "    return year_data\n",
    "\n",
    "# Function that splits data into training and test sets\n",
    "def split_xy(df, y_col):\n",
    "    \"\"\"Splits a dataframe into X and y components. The function assumes that the last column is the y variable.\"\"\"\n",
    "    X = df.drop(columns=[y_col])\n",
    "    y = df[y_col]\n",
    "    return [X, y]\n",
    "\n",
    "# Create sample function that only draws from specified values in a column\n",
    "def value_sample(df, col, value, sample_size):\n",
    "    \"\"\"Creates a dataframe that has a randome sample of observations that have specified value in\n",
    "    specified column. For example, if col = 'applicant_race_1' and value = 5 (which corresponds to white), \n",
    "    the sample will only have observations where the applicant is white.\"\"\" \n",
    "    sample = df[df[col] == value].sample(sample_size, random_state=313)\n",
    "    return sample\n",
    "\n",
    "# Function that create training data for white model and all race model, and test data for each race\n",
    "def model_samples(df, year_sample_size, test_sample_size, remove_race=True):\n",
    "    \"\"\"Fucntion that creates our training and test data for our ML models. If remove_race is true, the models will be \n",
    "    blind to the races of each application.\"\"\"\n",
    "    # First collect equal sized samples from each year\n",
    "    data_by_year = []\n",
    "    for year in range(2007, 2018):\n",
    "        year_dataset = set_year(df, year)\n",
    "        # Create training data for white and all race models\n",
    "        white_train = value_sample(year_dataset, 'applicant_race_1', 5, year_sample_size)\n",
    "        all_train = stratified_sample(year_dataset, 'applicant_race_1', year_sample_size)\n",
    "        if remove_race:\n",
    "            white_train = white_train.drop(columns=['applicant_race_1', 'co_applicant_race_1'])\n",
    "            all_train = all_train.drop(columns=['applicant_race_1', 'co_applicant_race_1'])\n",
    "        # Create test data for each race\n",
    "        race_tests = []\n",
    "        for race in range(1, 6):\n",
    "            race_sample = value_sample(year_dataset, 'applicant_race_1', race, test_sample_size)\n",
    "            if remove_race:\n",
    "                race_sample = race_sample.drop(columns=['applicant_race_1', 'co_applicant_race_1'])\n",
    "            race_tests.append(race_sample)\n",
    "        data_by_year.append([white_train, all_train, race_tests])\n",
    "    # Complied the data for each year\n",
    "    year_data = data_by_year.pop(0) \n",
    "    compiled_white = year_data[0]\n",
    "    compiled_all_race = year_data[1]\n",
    "    compiled_race_tests = year_data[2]  \n",
    "    while len(data_by_year) > 0:\n",
    "        year_data = data_by_year.pop(0)\n",
    "        compiled_white = pd.concat([compiled_white, year_data[0]], ignore_index=True)\n",
    "        compiled_all_race = pd.concat([compiled_all_race, year_data[1]], ignore_index=True)\n",
    "        for i in range(0, 5):\n",
    "            compiled_race_tests[i] = pd.concat([compiled_race_tests[i], year_data[2][i]], ignore_index=True)\n",
    "    return [compiled_white, compiled_all_race, compiled_race_tests]\n",
    "\n",
    "def model_testing(model, sample_data, y_col, cv=5, param_grid=None):\n",
    "    \"\"\"Fits white model and all race based on the specified training data. The y_col is the y variable column name.\n",
    "    The sample_data parameter is the output of the model_samples function and param_grid is the hyperparameter grid\n",
    "    that will be used in the GridSearchCV function. This function will return the results of the each model with given \n",
    "    parameters and the testing results from each race.\"\"\"\n",
    "    # Create the white model dataset\n",
    "    X_white, y_white = split_xy(sample_data[0], y_col)\n",
    "    # Create the all race model dataset\n",
    "    X_all, y_all = split_xy(sample_data[1], y_col)\n",
    "\n",
    "    # Set up Stratified K-Fold cross-validation\n",
    "    stratified_kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=313)\n",
    "    # Define scoring metrics\n",
    "    scoring = {'roc_auc': 'roc_auc', 'precision': 'precision', 'recall': 'recall', 'accuracy': 'accuracy'}\n",
    "\n",
    "    # Initialize GridSearchCV for White Only Model\n",
    "    white_search = GridSearchCV(model, param_grid, scoring=scoring, cv=stratified_kfold, refit='roc_auc', return_train_score=True)\n",
    "    white_search.fit(X_white, y_white)\n",
    "    # Initialize GridSearchCV for All Races Model\n",
    "    all_search = GridSearchCV(model, param_grid, scoring=scoring, cv=stratified_kfold, refit='roc_auc', return_train_score=True)\n",
    "    all_search.fit(X_all, y_all)\n",
    "\n",
    "    # Extract results for each model\n",
    "    white_results = pd.DataFrame(white_search.cv_results_)\n",
    "    all_results = pd.DataFrame(all_search.cv_results_)\n",
    "    # Add model type to results\n",
    "    white_results['Model'] = 'White only'\n",
    "    all_results['Model'] = 'All races'\n",
    "    # Combine results\n",
    "    combined_results = pd.concat([white_results, all_results])\n",
    "\n",
    "    # Sort combined results by index then drop\n",
    "    combined_results = combined_results.sort_index()\n",
    "\n",
    "    # Select relevant columns and rename them for clarity\n",
    "    relevant_columns = [f'param_{param}' for param in param_grid.keys()] + [\n",
    "        'mean_test_roc_auc', 'mean_test_precision', 'mean_test_recall', 'mean_test_accuracy', 'Model']\n",
    "    combined_results = combined_results[relevant_columns]\n",
    "\n",
    "    # Rename columns for final output\n",
    "    column_mapping = {f'param_{param}': param for param in param_grid.keys()}\n",
    "    column_mapping.update({\n",
    "        'mean_test_roc_auc': 'ROC-AUC Score',\n",
    "        'mean_test_precision': 'Precision',\n",
    "        'mean_test_recall': 'Recall',\n",
    "        'mean_test_accuracy': 'Accuracy'})\n",
    "    combined_results.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "    # Order the columns of so that Model is first\n",
    "    column_order = ['Model'] + [param for param in param_grid.keys()] + ['ROC-AUC Score', 'Precision', 'Recall', 'Accuracy']\n",
    "    combined_results = combined_results[column_order]\n",
    "\n",
    "    return combined_results\n",
    "\n",
    "# Remove rate spread from the dataset\n",
    "hmda_no_rate_spread = hmda_sample.drop(columns=['rate_spread'])\n",
    "\n",
    "# Adjust sample and test sizes for models and testing \n",
    "samples = model_samples(hmda_no_rate_spread, 1000, 200)\n",
    "\n",
    "# Set up model and hyperparameter grids\n",
    "logit = LogisticRegression(random_state=313)\n",
    "rforest = RandomForestClassifier(random_state=313)\n",
    "\n",
    "model_testing(rforest, samples, 'action_taken', param_grid={'max_depth': [3, 5], 'bootstrap': [True], 'max_samples':[100, 500]}, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapping = {\n",
    "    1: 'Alabama', 2: 'Alaska', 4: 'Arizona', 5: 'Arkansas', 6: 'California', 8: 'Colorado', \n",
    "    9: 'Connecticut', 10: 'Delaware', 11: 'District of Columbia', 12: 'Florida', 13: 'Georgia', \n",
    "    15: 'Hawaii', 16: 'Idaho', 17: 'Illinois', 18: 'Indiana', 19: 'Iowa', 20: 'Kansas', \n",
    "    21: 'Kentucky', 22: 'Louisiana', 23: 'Maine', 24: 'Maryland', 25: 'Massachusetts', \n",
    "    26: 'Michigan', 27: 'Minnesota', 28: 'Mississippi', 29: 'Missouri', 30: 'Montana', \n",
    "    31: 'Nebraska', 32: 'Nevada', 33: 'New Hampshire', 34: 'New Jersey', 35: 'New Mexico', \n",
    "    36: 'New York', 37: 'North Carolina', 38: 'North Dakota', 39: 'Ohio', 40: 'Oklahoma', \n",
    "    41: 'Oregon', 42: 'Pennsylvania', 44: 'Rhode Island', 45.0: 'South Carolina', 46: 'South Dakota', \n",
    "    47: 'Tennessee', 48: 'Texas', 49: 'Utah', 50: 'Vermont', 51: 'Virginia', 53: 'Washington', \n",
    "    54: 'West Virginia', 55: 'Wisconsin', 56: 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapping_reversed = {\n",
    "    'Alabama': 1, 'Alaska': 2, 'Arizona': 4, 'Arkansas': 5, 'California': 6, 'Colorado': 8,\n",
    "    'Connecticut': 9, 'Delaware': 10, 'District of Columbia': 11, 'Florida': 12, 'Georgia': 13,\n",
    "    'Hawaii': 15, 'Idaho': 16, 'Illinois': 17, 'Indiana': 18, 'Iowa': 19, 'Kansas': 20,\n",
    "    'Kentucky': 21, 'Louisiana': 22, 'Maine': 23, 'Maryland': 24, 'Massachusetts': 25,\n",
    "    'Michigan': 26, 'Minnesota': 27, 'Mississippi': 28, 'Missouri': 29, 'Montana': 30,\n",
    "    'Nebraska': 31, 'Nevada': 32, 'New Hampshire': 33, 'New Jersey': 34, 'New Mexico': 35,\n",
    "    'New York': 36, 'North Carolina': 37, 'North Dakota': 38, 'Ohio': 39, 'Oklahoma': 40,\n",
    "    'Oregon': 41, 'Pennsylvania': 42, 'Rhode Island': 44, 'South Carolina': 45.0, 'South Dakota': 46,\n",
    "    'Tennessee': 47, 'Texas': 48, 'Utah': 49, 'Vermont': 50, 'Virginia': 51, 'Washington': 53,\n",
    "    'West Virginia': 54, 'Wisconsin': 55, 'Wyoming': 56\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmda_sample['state_code'] = hmda_sample['state_code'].map(state_mapping_reversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20493630    45.0\n",
       "785654       6.0\n",
       "23721266     4.0\n",
       "11834421    39.0\n",
       "5852959      6.0\n",
       "            ... \n",
       "15768785    37.0\n",
       "10510466     8.0\n",
       "18606040    41.0\n",
       "23705045    48.0\n",
       "23385277     6.0\n",
       "Name: state_code, Length: 2486666, dtype: float64"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmda_sample['state_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ariana Timbol\\AppData\\Local\\Temp\\ipykernel_1656\\1140612214.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  all_race_state_df = hmda_sample.groupby(['applicant_race_1', 'state_code']).apply(lambda x: x.to_dict(orient='records')).unstack(fill_value=[])\n"
     ]
    }
   ],
   "source": [
    "# all_race_state_df = hmda_sample.groupby(['applicant_race_1', 'state_code']).apply(lambda x: x.to_dict(orient='records')).unstack(fill_value=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as_of_year</th>\n",
       "      <th>action_taken</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>loan_amount_000s</th>\n",
       "      <th>msamd</th>\n",
       "      <th>county_code</th>\n",
       "      <th>applicant_ethnicity</th>\n",
       "      <th>co_applicant_ethnicity</th>\n",
       "      <th>co_applicant_race_1</th>\n",
       "      <th>...</th>\n",
       "      <th>applicant_income_000s</th>\n",
       "      <th>purchaser_type</th>\n",
       "      <th>rate_spread</th>\n",
       "      <th>hoepa_status</th>\n",
       "      <th>population</th>\n",
       "      <th>minority_population</th>\n",
       "      <th>hud_median_family_income</th>\n",
       "      <th>tract_to_msamd_income</th>\n",
       "      <th>number_of_owner_occupied_units</th>\n",
       "      <th>number_of_1_to_4_family_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "      <td>2.486666e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.011078e+03</td>\n",
       "      <td>1.681597e-01</td>\n",
       "      <td>1.236123e+00</td>\n",
       "      <td>2.288440e+00</td>\n",
       "      <td>1.840260e+02</td>\n",
       "      <td>3.043349e+04</td>\n",
       "      <td>8.640120e+01</td>\n",
       "      <td>1.852879e+00</td>\n",
       "      <td>7.400962e-01</td>\n",
       "      <td>1.825391e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.012557e+01</td>\n",
       "      <td>5.268335e-01</td>\n",
       "      <td>-2.136762e-01</td>\n",
       "      <td>1.999160e+00</td>\n",
       "      <td>5.556639e+03</td>\n",
       "      <td>3.366403e+01</td>\n",
       "      <td>6.697421e+04</td>\n",
       "      <td>1.074395e+02</td>\n",
       "      <td>1.447721e+03</td>\n",
       "      <td>1.885659e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.375317e+00</td>\n",
       "      <td>3.740081e-01</td>\n",
       "      <td>5.249497e-01</td>\n",
       "      <td>8.884358e-01</td>\n",
       "      <td>3.617722e+02</td>\n",
       "      <td>1.125529e+04</td>\n",
       "      <td>1.007911e+02</td>\n",
       "      <td>3.542267e-01</td>\n",
       "      <td>9.375370e-01</td>\n",
       "      <td>2.328069e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.513403e+02</td>\n",
       "      <td>1.841884e+00</td>\n",
       "      <td>1.947055e+00</td>\n",
       "      <td>2.897197e-02</td>\n",
       "      <td>2.765717e+03</td>\n",
       "      <td>2.909032e+01</td>\n",
       "      <td>1.374192e+04</td>\n",
       "      <td>3.908267e+01</td>\n",
       "      <td>8.098524e+02</td>\n",
       "      <td>9.754884e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.007000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.014000e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.440000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.008000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.300000e+01</td>\n",
       "      <td>1.974000e+04</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.787000e+03</td>\n",
       "      <td>9.910000e+00</td>\n",
       "      <td>5.900000e+04</td>\n",
       "      <td>8.261000e+01</td>\n",
       "      <td>9.130000e+02</td>\n",
       "      <td>1.260000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.011000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.390000e+02</td>\n",
       "      <td>3.154000e+04</td>\n",
       "      <td>6.300000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.110000e+03</td>\n",
       "      <td>2.325000e+01</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>1.019400e+02</td>\n",
       "      <td>1.329000e+03</td>\n",
       "      <td>1.729000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.014000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.370000e+02</td>\n",
       "      <td>4.014000e+04</td>\n",
       "      <td>1.090000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>6.719000e+03</td>\n",
       "      <td>5.139000e+01</td>\n",
       "      <td>7.330000e+04</td>\n",
       "      <td>1.252200e+02</td>\n",
       "      <td>1.819000e+03</td>\n",
       "      <td>2.310000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.017000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.440000e+05</td>\n",
       "      <td>4.974000e+04</td>\n",
       "      <td>8.400000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>9.999000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.381200e+04</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.315000e+05</td>\n",
       "      <td>5.074700e+02</td>\n",
       "      <td>1.952900e+04</td>\n",
       "      <td>2.539100e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         as_of_year  action_taken     loan_type  loan_purpose  \\\n",
       "count  2.486666e+06  2.486666e+06  2.486666e+06  2.486666e+06   \n",
       "mean   2.011078e+03  1.681597e-01  1.236123e+00  2.288440e+00   \n",
       "std    3.375317e+00  3.740081e-01  5.249497e-01  8.884358e-01   \n",
       "min    2.007000e+03  0.000000e+00  1.000000e+00  1.000000e+00   \n",
       "25%    2.008000e+03  0.000000e+00  1.000000e+00  1.000000e+00   \n",
       "50%    2.011000e+03  0.000000e+00  1.000000e+00  3.000000e+00   \n",
       "75%    2.014000e+03  0.000000e+00  1.000000e+00  3.000000e+00   \n",
       "max    2.017000e+03  1.000000e+00  4.000000e+00  3.000000e+00   \n",
       "\n",
       "       loan_amount_000s         msamd   county_code  applicant_ethnicity  \\\n",
       "count      2.486666e+06  2.486666e+06  2.486666e+06         2.486666e+06   \n",
       "mean       1.840260e+02  3.043349e+04  8.640120e+01         1.852879e+00   \n",
       "std        3.617722e+02  1.125529e+04  1.007911e+02         3.542267e-01   \n",
       "min        1.000000e+00  1.014000e+04  1.000000e+00         1.000000e+00   \n",
       "25%        7.300000e+01  1.974000e+04  2.900000e+01         2.000000e+00   \n",
       "50%        1.390000e+02  3.154000e+04  6.300000e+01         2.000000e+00   \n",
       "75%        2.370000e+02  4.014000e+04  1.090000e+02         2.000000e+00   \n",
       "max        3.440000e+05  4.974000e+04  8.400000e+02         2.000000e+00   \n",
       "\n",
       "       co_applicant_ethnicity  co_applicant_race_1  ...  \\\n",
       "count            2.486666e+06         2.486666e+06  ...   \n",
       "mean             7.400962e-01         1.825391e+00  ...   \n",
       "std              9.375370e-01         2.328069e+00  ...   \n",
       "min              0.000000e+00         0.000000e+00  ...   \n",
       "25%              0.000000e+00         0.000000e+00  ...   \n",
       "50%              0.000000e+00         0.000000e+00  ...   \n",
       "75%              2.000000e+00         5.000000e+00  ...   \n",
       "max              2.000000e+00         5.000000e+00  ...   \n",
       "\n",
       "       applicant_income_000s  purchaser_type   rate_spread  hoepa_status  \\\n",
       "count           2.486666e+06    2.486666e+06  2.486666e+06  2.486666e+06   \n",
       "mean            9.012557e+01    5.268335e-01 -2.136762e-01  1.999160e+00   \n",
       "std             1.513403e+02    1.841884e+00  1.947055e+00  2.897197e-02   \n",
       "min             1.000000e+00    0.000000e+00 -1.000000e+00  1.000000e+00   \n",
       "25%             4.100000e+01    0.000000e+00 -1.000000e+00  2.000000e+00   \n",
       "50%             6.500000e+01    0.000000e+00 -1.000000e+00  2.000000e+00   \n",
       "75%             1.020000e+02    0.000000e+00 -1.000000e+00  2.000000e+00   \n",
       "max             6.500000e+04    9.000000e+00  9.999000e+01  2.000000e+00   \n",
       "\n",
       "         population  minority_population  hud_median_family_income  \\\n",
       "count  2.486666e+06         2.486666e+06              2.486666e+06   \n",
       "mean   5.556639e+03         3.366403e+01              6.697421e+04   \n",
       "std    2.765717e+03         2.909032e+01              1.374192e+04   \n",
       "min    0.000000e+00         0.000000e+00              1.440000e+04   \n",
       "25%    3.787000e+03         9.910000e+00              5.900000e+04   \n",
       "50%    5.110000e+03         2.325000e+01              6.500000e+04   \n",
       "75%    6.719000e+03         5.139000e+01              7.330000e+04   \n",
       "max    5.381200e+04         1.000000e+02              1.315000e+05   \n",
       "\n",
       "       tract_to_msamd_income  number_of_owner_occupied_units  \\\n",
       "count           2.486666e+06                    2.486666e+06   \n",
       "mean            1.074395e+02                    1.447721e+03   \n",
       "std             3.908267e+01                    8.098524e+02   \n",
       "min             0.000000e+00                    0.000000e+00   \n",
       "25%             8.261000e+01                    9.130000e+02   \n",
       "50%             1.019400e+02                    1.329000e+03   \n",
       "75%             1.252200e+02                    1.819000e+03   \n",
       "max             5.074700e+02                    1.952900e+04   \n",
       "\n",
       "       number_of_1_to_4_family_units  \n",
       "count                   2.486666e+06  \n",
       "mean                    1.885659e+03  \n",
       "std                     9.754884e+02  \n",
       "min                     0.000000e+00  \n",
       "25%                     1.260000e+03  \n",
       "50%                     1.729000e+03  \n",
       "75%                     2.310000e+03  \n",
       "max                     2.539100e+04  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_mapping = {5: 'White', 3: 'Black or African American', 2: 'Asian', 1: 'American Indian or Alaska Native', 4: 'Native Hawaiian or Other Pacific Islander'}\n",
    "hmda_sample['action_taken'] = hmda_sample['action_taken'].apply(lambda x: 1 if x in [1, 2] else 0)\n",
    "hmda_sample['applicant_race_1'] = hmda_sample['applicant_race_1'].map(race_mapping)\n",
    "hmda_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20493630                               White\n",
       "785654                                 White\n",
       "23721266                               White\n",
       "11834421           Black or African American\n",
       "5852959     American Indian or Alaska Native\n",
       "                          ...               \n",
       "15768785           Black or African American\n",
       "10510466                               White\n",
       "18606040                               White\n",
       "23705045                               White\n",
       "23385277                               White\n",
       "Name: applicant_race_1, Length: 2486666, dtype: object"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmda_sample['applicant_race_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def race_state_dict(df, race_col, state_col, value_col):\n",
    "#     race_state_dict = {}\n",
    "\n",
    "#     # Group by race\n",
    "#     grouped_by_race = df.groupby(race_col)\n",
    "\n",
    "#     for race, race_group in grouped_by_race:\n",
    "#         race_state_dict[race] = {}\n",
    "\n",
    "#         # Group by state within each race\n",
    "#         grouped_by_state = race_group.groupby(state_col)\n",
    "\n",
    "#         for state, state_group in grouped_by_state:\n",
    "#             # Store the values as a list for each state under each race\n",
    "#             race_state_dict[race][state] = state_group[value_col].tolist()\n",
    "\n",
    "#     return race_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_state_dict(df, race_col, state_col):\n",
    "    race_state_dict = {}\n",
    "\n",
    "    # Group by race\n",
    "    grouped_by_race = df.groupby(race_col)\n",
    "\n",
    "    for race, race_group in grouped_by_race:\n",
    "        race_state_dict[race] = {}\n",
    "\n",
    "        # Group by state within each race\n",
    "        grouped_by_state = race_group.groupby(state_col)\n",
    "\n",
    "        for state, state_group in grouped_by_state:\n",
    "            # Store the entire row (all columns) as a list of lists for each state under each race\n",
    "            race_state_dict[race][state] = state_group.values.tolist()\n",
    "\n",
    "    return race_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_state_dictionary = race_state_dict(hmda_sample, 'applicant_race_1', 'state_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_model_samples(df, year_sample_size, test_sample_size, remove_race=True):\n",
    "    # Create empty lists for all race and white race models\n",
    "    all_race_data = []\n",
    "    white_race_data = []\n",
    "    \n",
    "    # Loop over all the states (50 states)\n",
    "    states = df['state_code'].unique()\n",
    "\n",
    "    # Iterate over each state and collect data\n",
    "    for state in states:\n",
    "        state_data = df[df['state_code'] == state] \n",
    "        \n",
    "        # Create training data for all races and white race models for this state\n",
    "        all_train_state = stratified_sample(state_data, 'applicant_race_1', year_sample_size) \n",
    "        white_train_state = value_sample(state_data, 'applicant_race_1', 'White', year_sample_size) \n",
    "        \n",
    "        if remove_race:\n",
    "            all_train_state = all_train_state.drop(columns=['applicant_race_1', 'co_applicant_race_1'])\n",
    "            white_train_state = white_train_state.drop(columns=['applicant_race_1', 'co_applicant_race_1'])\n",
    "        \n",
    "        \n",
    "        race_tests_all = [] \n",
    "        race_tests_white = [] \n",
    "        \n",
    "       \n",
    "        for race in df['applicant_race_1']:\n",
    "            race_data = state_data[state_data['applicant_race_1'] == race] \n",
    "            \n",
    "            # Adjust the sample size if there is not enough data\n",
    "            if len(race_data) < test_sample_size:\n",
    "                race_sample_size = len(race_data)  \n",
    "            else:\n",
    "                race_sample_size = test_sample_size \n",
    "            \n",
    "            # Sample data if there is data available\n",
    "            if race_sample_size > 0:\n",
    "                race_sample = value_sample(race_data, 'applicant_race_1', race, race_sample_size)\n",
    "                \n",
    "                if remove_race:\n",
    "                    race_sample = race_sample.drop(columns=['applicant_race_1', 'co_applicant_race_1'])\n",
    "                \n",
    "                # Append race test data for \"all races\" and \"white race\"\n",
    "                if race == 'White':  \n",
    "                    race_tests_white.append(race_sample)\n",
    "                else:  # White race (race 5)\n",
    "                    race_tests_all.append(race_sample)\n",
    "            else:\n",
    "                if race == 'White':\n",
    "                    race_tests_white.append(pd.DataFrame())  # All races\n",
    "                else:\n",
    "                    race_tests_all.append(pd.DataFrame())  # White race\n",
    "\n",
    "       \n",
    "        all_race_data.append(race_tests_all)\n",
    "        white_race_data.append(race_tests_white)\n",
    "    \n",
    "    return [all_race_data, white_race_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_samples = state_model_samples(hmda_sample, 1000, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state=313)\n",
    "rforest = RandomForestClassifier(random_state=313)\n",
    "\n",
    "model_testing(rforest, state_samples, 'action_taken', param_grid={'max_depth': [3, 5], 'bootstrap': [True], 'max_samples':[100, 500]}, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def equal_sample_for_each_key_and_innerkey(data_dict, sample_size):\n",
    "#     \"\"\"Samples equal number of elements for each race and state in the dictionary.\"\"\"\n",
    "#     sampled_dict = {}\n",
    "    \n",
    "#     for race, states in data_dict.items():\n",
    "#         sampled_dict[race] = {}\n",
    "        \n",
    "#         for state, values in states.items():\n",
    "#             # Ensure there are enough values to sample\n",
    "#             if len(values) >= sample_size:\n",
    "#                 sampled_dict[race][state] = random.sample(values, sample_size)\n",
    "#             else:\n",
    "#                 sampled_dict[race][state] = values  # Use all data if not enough to sample\n",
    "    \n",
    "#     return sampled_dict\n",
    "\n",
    "# def create_dataframe(data_dict, sample_size):\n",
    "#     \"\"\"Creates a DataFrame from the sampled data.\"\"\"\n",
    "#     # First, sample the data for each race and state\n",
    "#     sampled_data = equal_sample_for_each_key_and_innerkey(data_dict, sample_size)\n",
    "    \n",
    "#     # Create a list of rows for DataFrame\n",
    "#     rows = []\n",
    "#     for race, states in sampled_data.items():\n",
    "#         for state, values in states.items():\n",
    "#             for value in values:\n",
    "#                 # Add each value as a row with race and state as columns\n",
    "#                 rows.append([race, state, value])\n",
    "    \n",
    "#     # Create a DataFrame\n",
    "#     df = pd.DataFrame(rows, columns=['Race', 'State', 'action_taken'])\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_state = create_dataframe(race_state_dictionary, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "      <th>State</th>\n",
       "      <th>action_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90269</th>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90270</th>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90271</th>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90272</th>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90273</th>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90274 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Race    State  action_taken\n",
       "0      American Indian or Alaska Native  Alabama             0\n",
       "1      American Indian or Alaska Native  Alabama             0\n",
       "2      American Indian or Alaska Native  Alabama             0\n",
       "3      American Indian or Alaska Native  Alabama             0\n",
       "4      American Indian or Alaska Native  Alabama             0\n",
       "...                                 ...      ...           ...\n",
       "90269                             White  Wyoming             0\n",
       "90270                             White  Wyoming             0\n",
       "90271                             White  Wyoming             0\n",
       "90272                             White  Wyoming             0\n",
       "90273                             White  Wyoming             0\n",
       "\n",
       "[90274 rows x 3 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# race_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_train_test(data_dict, train_size=0.8):\n",
    "#     \"\"\"Splits the data into training and testing sets for each race and state.\"\"\"\n",
    "#     train_dict = {}\n",
    "#     test_dict = {}\n",
    "\n",
    "#     # Iterate over each race in the dictionary\n",
    "#     for race, states in data_dict.items():\n",
    "#         train_dict[race] = {}\n",
    "#         test_dict[race] = {}\n",
    "\n",
    "#         # Iterate over each state within the race\n",
    "#         for state, values in states.items():\n",
    "#             # Calculate the split index\n",
    "#             split_idx = int(len(values) * train_size)\n",
    "#             # Split the values into training and testing sets\n",
    "#             train_dict[race][state] = values[:split_idx]\n",
    "#             test_dict[race][state] = values[split_idx:]\n",
    "    \n",
    "#     return train_dict, test_dict\n",
    "\n",
    "# def create_dataframe(data_dict, sample_size, train_size):\n",
    "#     \"\"\"Creates a DataFrame from the sampled and split data for each race (including white and all races).\"\"\"\n",
    "#     # First, sample the data for each race and state\n",
    "#     sampled_data = equal_sample_for_each_key_and_innerkey(data_dict, sample_size)\n",
    "    \n",
    "#     # Now, split the data into training and testing sets\n",
    "#     train_data, test_data = split_train_test(sampled_data, train_size)\n",
    "    \n",
    "#     # Create DataFrames for each category (white and all races)\n",
    "#     white_train_data = train_data.get(5, {})  # Assuming race '5' is White\n",
    "#     white_test_data = test_data.get(5, {})    # Assuming race '5' is White\n",
    "    \n",
    "#     # For all races, combine the data\n",
    "#     all_race_train_data = {race: states for race, states in train_data.items()}\n",
    "#     all_race_test_data = {race: states for race, states in test_data.items()}\n",
    "\n",
    "#     # Helper function to convert dictionary to a DataFrame\n",
    "#     def dict_to_dataframe(data_dict, label):\n",
    "#         rows = []\n",
    "#         for race, states in data_dict.items():\n",
    "#             for state, values in states.items():\n",
    "#                 for value in values:\n",
    "#                     rows.append([label, race, state, value])\n",
    "#         return pd.DataFrame(rows, columns=['Model', 'Race', 'State', 'action_taken'])\n",
    "    \n",
    "#     # Create DataFrames for white and all races\n",
    "#     white_train_df = dict_to_dataframe(white_train_data, 'White Train')\n",
    "#     white_test_df = dict_to_dataframe(white_test_data, 'White Test')\n",
    "#     all_race_train_df = dict_to_dataframe(all_race_train_data, 'All Race Train')\n",
    "#     all_race_test_df = dict_to_dataframe(all_race_test_data, 'All Race Test')\n",
    "\n",
    "#     # Combine all the DataFrames into a single DataFrame\n",
    "#     final_df = pd.concat([white_train_df, white_test_df, all_race_train_df, all_race_test_df], ignore_index=True)\n",
    "\n",
    "#     return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_sample = create_dataframe(race_state_dictionary, 200, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Race</th>\n",
       "      <th>State</th>\n",
       "      <th>action_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42108</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42109</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42110</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42111</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42112</th>\n",
       "      <td>All Race Train</td>\n",
       "      <td>White</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42113 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model                              Race    State action_taken\n",
       "0      All Race Train  American Indian or Alaska Native  Alabama            0\n",
       "1      All Race Train  American Indian or Alaska Native  Alabama            0\n",
       "2      All Race Train  American Indian or Alaska Native  Alabama            0\n",
       "3      All Race Train  American Indian or Alaska Native  Alabama            0\n",
       "4      All Race Train  American Indian or Alaska Native  Alabama            0\n",
       "...               ...                               ...      ...          ...\n",
       "42108  All Race Train                             White  Wyoming            0\n",
       "42109  All Race Train                             White  Wyoming            1\n",
       "42110  All Race Train                             White  Wyoming            0\n",
       "42111  All Race Train                             White  Wyoming            0\n",
       "42112  All Race Train                             White  Wyoming            0\n",
       "\n",
       "[42113 rows x 4 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# race_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_xy_state(data, y_col):\n",
    "#     \"\"\"Splits the data into X (features) and y (target) based on the target column (y_col).\"\"\"\n",
    "#     X = data.drop(columns=[y_col])\n",
    "#     y = data[y_col]\n",
    "#     return X, y\n",
    "\n",
    "# def model_testing_state(model, sample_data, y_col, cv=5, param_grid=None):\n",
    "#     \"\"\"Fits white model and all race based on the specified training data. \n",
    "#     The y_col is the y variable column name.\n",
    "#     The sample_data parameter is the output of the model_samples function, \n",
    "#     and param_grid is the hyperparameter grid used in GridSearchCV.\n",
    "#     This function will return the results of each model with given parameters \n",
    "#     and the testing results from each race.\"\"\"\n",
    "    \n",
    "#     # Create the white model dataset\n",
    "#     X_white, y_white = split_xy(sample_data[1], y_col)\n",
    "#     # Create the all race model dataset\n",
    "#     X_all, y_all = split_xy(sample_data[2], y_col)\n",
    "\n",
    "#     # Set up Stratified K-Fold cross-validation\n",
    "#     stratified_kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=313)\n",
    "    \n",
    "#     # Define scoring metrics\n",
    "#     scoring = {'roc_auc': 'roc_auc', 'precision': 'precision', 'recall': 'recall', 'accuracy': 'accuracy'}\n",
    "    \n",
    "#     # Initialize GridSearchCV for White Only Model\n",
    "#     white_search = GridSearchCV(model, param_grid, scoring=scoring, cv=stratified_kfold, refit='roc_auc', return_train_score=True)\n",
    "#     white_search.fit(X_white, y_white)\n",
    "    \n",
    "#     # Initialize GridSearchCV for All Races Model\n",
    "#     all_search = GridSearchCV(model, param_grid, scoring=scoring, cv=stratified_kfold, refit='roc_auc', return_train_score=True)\n",
    "#     all_search.fit(X_all, y_all)\n",
    "\n",
    "#     # Extract results for each model\n",
    "#     white_results = pd.DataFrame(white_search.cv_results_)\n",
    "#     all_results = pd.DataFrame(all_search.cv_results_)\n",
    "    \n",
    "#     # Add model type to results\n",
    "#     white_results['Model'] = 'White only'\n",
    "#     all_results['Model'] = 'All races'\n",
    "    \n",
    "#     # Combine results\n",
    "#     combined_results = pd.concat([white_results, all_results])\n",
    "\n",
    "#     # Sort combined results by index\n",
    "#     combined_results = combined_results.sort_index()\n",
    "\n",
    "#     # Select relevant columns and rename them for clarity\n",
    "#     relevant_columns = [f'param_{param}' for param in param_grid.keys()] + [\n",
    "#         'mean_test_roc_auc', 'mean_test_precision', 'mean_test_recall', 'mean_test_accuracy', 'Model']\n",
    "#     combined_results = combined_results[relevant_columns]\n",
    "\n",
    "#     # Rename columns for final output\n",
    "#     column_mapping = {f'param_{param}': param for param in param_grid.keys()}\n",
    "#     column_mapping.update({\n",
    "#         'mean_test_roc_auc': 'ROC-AUC Score',\n",
    "#         'mean_test_precision': 'Precision',\n",
    "#         'mean_test_recall': 'Recall',\n",
    "#         'mean_test_accuracy': 'Accuracy'})\n",
    "    \n",
    "#     combined_results.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "#     # Order the columns of so that Model is first\n",
    "#     column_order = ['Model'] + [param for param in param_grid.keys()] + ['ROC-AUC Score', 'Precision', 'Recall', 'Accuracy']\n",
    "#     combined_results = combined_results[column_order]\n",
    "\n",
    "#     return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[238], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_testing(rforest, race_sample, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m, param_grid\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_samples\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m]}, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[204], line 16\u001b[0m, in \u001b[0;36mmodel_testing\u001b[1;34m(model, sample_data, y_col, cv, param_grid)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits white model and all race based on the specified training data. \u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mThe y_col is the y variable column name.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mThe sample_data parameter is the output of the model_samples function, \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mand param_grid is the hyperparameter grid used in GridSearchCV.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03mThis function will return the results of each model with given parameters \u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mand the testing results from each race.\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Create the white model dataset\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m X_white, y_white \u001b[38;5;241m=\u001b[39m split_xy(sample_data[\u001b[38;5;241m0\u001b[39m], y_col)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create the all race model dataset\u001b[39;00m\n\u001b[0;32m     18\u001b[0m X_all, y_all \u001b[38;5;241m=\u001b[39m split_xy(sample_data[\u001b[38;5;241m1\u001b[39m], y_col)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# model_testing(rforest, race_sample, 'State', param_grid={'max_depth': [3, 5], 'bootstrap': [True], 'max_samples':[100, 500]}, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_states(df):\n",
    "    \n",
    "#     all_race_state_list = []\n",
    "\n",
    "#     for race in df.index:\n",
    "    \n",
    "#         race_data = [race] \n",
    "#         for state in df.columns:\n",
    "       \n",
    "#             race_data.append(df.loc[race, state])\n",
    "    \n",
    "   \n",
    "#         all_race_state_list.append(race_data)\n",
    "\n",
    "\n",
    "#     return all_race_state_list[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_state = sample_states(all_race_state_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Two nested lists containing every state \n",
    "# def dict_states(df):\n",
    "#     all_race_data = {\n",
    "#         1: {\n",
    "#         },\n",
    "#         2: {},\n",
    "#         5: {},\n",
    "#         3: {},\n",
    "#         4: {}\n",
    "#     }\n",
    "\n",
    "#     # for race in df['applicant_race_1']:\n",
    "#     #     for state in df['state_code']:            \n",
    "#     #         if not all_race_data[race][state]:\n",
    "#     #             all_race_data[race][state] = []\n",
    "\n",
    "#     for race in df['applicant_race_1']:  # Use .unique() to ensure no duplicates\n",
    "#         if race not in all_race_data:\n",
    "#             all_race_data[race] = {}  # Initialize an empty dictionary for each race\n",
    "\n",
    "#         # Iterate through each unique state in the dataset\n",
    "#         for state in df['state_code'].unique():  # Use .unique() to ensure no duplicates\n",
    "#             if state not in all_race_data[race]:\n",
    "#                 all_race_data[race][state] = []  \n",
    "\n",
    "\n",
    "#     for i in range(len(df)):\n",
    "#         race = df.loc[i, \"applicant_race_1\"]\n",
    "#         state = df.loc[i, \"state_code\"]\n",
    "#         data_value = df.loc[i, \"action_taken\"] \n",
    "#         all_race_data[race][state].append([data_value])\n",
    "\n",
    "#     return all_race_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dict_states(hmda_sample)\n",
      "Cell \u001b[1;32mIn[95], line 22\u001b[0m, in \u001b[0;36mdict_states\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     19\u001b[0m     all_race_data[race] \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# Initialize an empty dictionary for each race\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Iterate through each unique state in the dataset\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():  \u001b[38;5;66;03m# Use .unique() to ensure no duplicates\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_race_data[race]:\n\u001b[0;32m     24\u001b[0m         all_race_data[race][state] \u001b[38;5;241m=\u001b[39m []  \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:2407\u001b[0m, in \u001b[0;36mSeries.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[0;32m   2345\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[0;32m   2347\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2405\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[0;32m   2406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:1025\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1025\u001b[0m     result \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39munique1d(values)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:401\u001b[0m, in \u001b[0;36munique\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unique_with_mask(values)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:441\u001b[0m, in \u001b[0;36munique_with_mask\u001b[1;34m(values, mask)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    440\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39munique(values)\n\u001b[1;32m--> 441\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:184\u001b[0m, in \u001b[0;36m_reconstruct_data\u001b[1;34m(values, dtype, original)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_object(values)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reconstruct_data\u001b[39m(\n\u001b[0;32m    185\u001b[0m     values: ArrayLike, dtype: DtypeObj, original: AnyArrayLike\n\u001b[0;32m    186\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m    reverse of _ensure_data\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    ExtensionArray or np.ndarray\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ABCExtensionArray) \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtype:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;66;03m# Catch DatetimeArray/TimedeltaArray\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dict_states(hmda_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_states(df, year_sample_size, test_sample_size, remove = True):\n",
    "\n",
    "# # Creating training data for white and all race data\n",
    "#      all_race_data_list = []\n",
    "#      white_race_data_list = []\n",
    "\n",
    "#     # Iterate through each state\n",
    "#      for state in df['state_code']:\n",
    "#         # Create lists to store the sampled data for all races and for \"White\" race\n",
    "#         all_state_data = []\n",
    "#         white_state_data = []\n",
    "        \n",
    "#         # Sample for \"White\" race using value_sample function\n",
    "#         white_sample = value_sample(df, 'applicant_race_1', 5, year_sample_size)  \n",
    "#         white_state_data = white_sample[white_sample['state_code'] == state]\n",
    "\n",
    "#         # Add the sampled white race data to the white_race_data_list\n",
    "#         white_race_data_list.append(white_state_data)\n",
    "\n",
    "#         # For other races, sample using stratified sampling\n",
    "#         all_race_sample = stratified_sample(df, 'applicant_race_1', year_sample_size)\n",
    "#         all_state_data = all_race_sample[all_race_sample['state_code'] == state]\n",
    "\n",
    "#         # Add the sampled all races data to the all_race_data_list\n",
    "#         all_race_data_list.append(all_state_data)\n",
    "\n",
    "\n",
    "#     #Testing data\n",
    "#      race_tests = []\n",
    "#      for race in range(1, 6):  # Iterate through races 1 to 5\n",
    "#     # Get the sampled data for the specific race\n",
    "#         race_sample = value_sample(year_dataset, 'applicant_race_1', race, test_sample_size)\n",
    "#         testing_data = all_race_sample[all_race_sample['state_code'] == state]\n",
    "#     # # If remove_race is True, drop the race columns\n",
    "#     #     if remove_race:\n",
    "#     #         race_sample = race_sample.drop(columns=['applicant_race_1', 'co_applicant_race_1'])\n",
    "#     # Append the race sample to the race_tests list\n",
    "#         race_tests.append(testing_data)\n",
    "#     # Append the results to the data_by_year list\n",
    "#      data_for_df.append([White_train, All_train, race_tests])\n",
    "\n",
    "#      return [all_race_data_list, white_race_data_list, race_tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_samples = sample_states(all_race_state_df, 200, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Two lists containing every state \n",
    "# all_race_data = {}\n",
    "\n",
    "# for race in hmda_sample['applicant_race_1']: \n",
    "#     if race not in all_race_data:\n",
    "#         all_race_data[race] = {} \n",
    "\n",
    "#     # Iterate through each unique state in the dataset\n",
    "#     for state in hmda_sample['state_code']:  \n",
    "#         if state not in all_race_data[race]:\n",
    "#             all_race_data[race][state] = []  \n",
    "\n",
    "\n",
    "# for i in range(len(hmda_sample)):\n",
    "#     race = df.loc[i, \"applicant_race_1\"]\n",
    "#     state = df.loc[i, \"state_code\"]\n",
    "#     data_value = df.loc[i, \"action_taken\"] \n",
    "#     all_race_data[race][state].append([data_value])\n",
    "\n",
    "# all_race_state_df = pd.DataFrame(all_race_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust sample and test sizes for models and testing \n",
    "# state_samples = sample_states(hmda_no_rate_spread, 200, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
